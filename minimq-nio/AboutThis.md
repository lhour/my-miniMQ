#
使用 java nio, 图省事上了全索引，数据少的话还能玩玩。

## 题目分析

根据实例文件，可以看出就是要实现两个方法。

1. 写，写的时候要对写入内容分组，先分 `topic` ，再分 `queue` ，然后还要排序编号`offset`，而主要的存储的内容就是一个`byte[]`类型的数据。
2. 读，指定 `topic` 和 `queue` ，返回指定的数据。

```
//而且我们要保存到本地，能在关机后数据得到及时保存。

//而且是多线程的读写。

//而且会发生一遍读一遍写的情况。

//。。。
```

## 设计思路与理论验证

存储：

1. 使用一个文件来存储索引，记录下每一个 `queue` 下的 `data` 所在的字节位置及其长度。
2. 使用一个文件来存储 `data`

写入：

1. 每次开启服务时，将索引文件全部读入缓存，开设一条线程每过一定时间更新索引文件。

2. 同时开启一条写入的流。

3. 使用一个流用来写入文件，再一个全局变量记录当前末尾字节位置数。

4. 这里应该加个锁，当线程来写时，写入同时更新缓存的索引，记录某条数据位置及长度。

5. 在读文件时，先从索引中查找，查找到后开启一个局部流进行读取操作。

6. 可以使用 `ConcurrentHashMap` 来实现索引。

   

计算：

1. 首先要存入`125GiB`数据，转换为`Byte`，得 `134,217,728,000` 也就是说存储定位时，使用int类型是不够的

2. `nio`把千万字节读入缓存要`0.5s`（9个0，以后均使用9个0做测试），而总数据大小11个0，也就是 50s。感觉要超时。

   

优化：

1. 考虑`ByteBuffer`性能，可能分多次读会使性能变好？ √
   1. 根据测试，读取10000个字节后，清除缓存在读入，会使得速度提升一倍
   2. 读取 100 000个字节， 循环10 000次，只要 `60ms`， 再提升三倍
   3. 7 和 4 组合最佳 
2. 除了这个地方，还要考虑的是，读是多线程的，读的时候同时开启多个通道，抗的住吗？
   1. 实验开始``ThreadRead.java`
   2. 50个线程，最多只要`300ms`



## V 1.0.0
   在数据达到一定数量时，索引的存储会变成极大的负担。
   性能极差，大概只能存储百万条小字符串，长字符串更少了
   
## v 1.0.1
   索引优化

## bug记录

1.Map contionsKey 用成 contions 导致存数据时直接给覆盖了 ==== 9.12
2.Map key 的类型必须一致，否则查询不到 ====9.13
3.每次从索引中读取了原Map，而又从源代码中更改了 Map 结构，不会报错 ==== 9.13

